{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7279797,"sourceType":"datasetVersion","datasetId":4220866}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers,models\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras import optimizers, losses , metrics\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# System libraries\nfrom pathlib import Path\nimport os.path\n\n# Metrics\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_value = 0\nnp.random.seed(seed_value)\ntf.random.set_seed(seed_value)\nrandom.seed(seed_value)\nos.environ['PYTHONHASHSEED'] = str(seed_value)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = \"../input/seaanimals\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_dir = Path(data)\n\n# Get filepaths and labels\nfilepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png')) + list(image_dir.glob(r'**/*.PNG'))\n\nlabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n\nfilepaths = pd.Series(filepaths, name='Filepath').astype(str)\nlabels = pd.Series(labels, name='Label')\n\n# Concatenate filepaths and labels\nimage_df = pd.concat([filepaths, labels], axis=1)\nimage_df = image_df.groupby('Label').apply(lambda x: x.sample(n=min(498, len(x)))).reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import PIL\nfrom pathlib import Path\nfrom PIL import UnidentifiedImageError\n\npath = Path(\"../input/sea-animals-image-dataste\").rglob(\"*.jpg\")\nfor img_p in path:\n    try:\n        img = PIL.Image.open(img_p)\n    except PIL.UnidentifiedImageError:\n            print(img_p)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display 16 picture of the dataset with their labels\nrandom_index = np.random.randint(0, len(image_df), 16)\nfig, axes = plt.subplots(nrows=4, ncols=4, figsize=(10, 10),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(image_df.Filepath[random_index[i]]))\n    ax.set_title(image_df.Label[random_index[i]])\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(data=image_df, x='Label')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set random seed for reproducibility\nseed_value = 42\n\n# 1. Set the `PYTHONHASHSEED` environment variable\nos.environ['PYTHONHASHSEED'] = str(seed_value)\n\n# 2. Set the `python` built-in pseudo-random generator at a fixed value\nnp.random.seed(seed_value)\n\n# 3. Set the `tensorflow` pseudo-random generator at a fixed value\ntf.random.set_seed(seed_value)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2,\n                                  shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True, fill_mode = 'nearest',\n    validation_split=0.2) # set validation split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = train_datagen.flow_from_directory(\n    data,\n    target_size=(224, 224),\n    batch_size=48,\n    class_mode='categorical',\n    subset='training') # set as training data\n\nvalidation_images = train_datagen.flow_from_directory(\n    data , # same directory as training data\n    target_size=(224, 224),\n    batch_size=48,\n    class_mode='categorical',\n    subset='validation') # set as validation data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobile_model = Sequential()\n\npretrained_model = tf.keras.applications.MobileNetV2(\n    input_shape=(224, 224, 3),\n    include_top=False,\n    weights='imagenet',\n    pooling='avg'\n)\npretrained_model.trainable = False\nmobile_model.add(pretrained_model)\nmobile_model.add(Flatten())\nmobile_model.add(Dense(512, activation='relu'))\nmobile_model.add(Dropout(0.5))\nmobile_model.add(Dense(6, activation='softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobile_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobile_model.compile(loss = 'categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(), metrics = ['accuracy' , metrics.Precision(), metrics.Recall()])\n\n# history = mobile_model.fit(train_images,\n#     steps_per_epoch=len(train_images),\n#     validation_data=validation_images,\n#     validation_steps=len(validation_images),\n#     epochs=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nall_validation_accuracy = []\nall_validation_loss = []\nall_precision = []\nall_recall = []\n# Define the number of folds\nnum_folds = 3  # You can change this value based on your preference\n\n# Create a StratifiedKFold object\nkf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=seed_value)\n\n# Iterate over the folds\nfold = 0\nfor train_index, val_index in kf.split(image_df.Filepath, image_df.Label):\n    fold += 1\n    print(f\"Training on Fold {fold}\")\n    history = mobile_model.fit(train_images, steps_per_epoch=len(train_images), validation_data=validation_images, validation_steps=len(validation_images), epochs=20)\n\n    # Store validation accuracy and loss\n    validation_loss, validation_accuracy , precision , recall= mobile_model.evaluate(validation_images, steps=len(validation_images))\n    all_validation_accuracy.append(validation_accuracy)\n    all_validation_loss.append(validation_loss)\n    all_precision.append(precision)\n    all_recall.append(precision)\n\n    # Plot the accuracy/loss graphs for each fold\n    history_dict = history.history\n    loss_values = history_dict['loss']\n    val_loss_values = history_dict['val_loss']\n    accuracy = history_dict['accuracy']\n    val_accuracy = history_dict['val_accuracy']\n\n    epochs = range(1, len(loss_values) + 1)\n    fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n\n    # Plot the model accuracy vs Epochs\n    ax[0].plot(epochs, accuracy, 'r', label='Training accuracy')\n    ax[0].plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n    ax[0].set_title(f'Training & Validation Accuracy - Fold {fold}', fontsize=16)\n    ax[0].set_xlabel('Epochs', fontsize=16)\n    ax[0].set_ylabel('Accuracy', fontsize=16)\n    ax[0].legend()\n\n    # Plot the loss vs Epochs\n    ax[1].plot(epochs, loss_values, 'r', label='Training loss')\n    ax[1].plot(epochs, val_loss_values, 'b', label='Validation loss')\n    ax[1].set_title(f'Training & Validation Loss - Fold {fold}', fontsize=16)\n    ax[1].set_xlabel('Epochs', fontsize=16)\n    ax[1].set_ylabel('Loss', fontsize=16)\n    ax[1].legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_fold = np.argmax(all_validation_accuracy) + 1  # +1 because folds are 1-indexed\nprint(f'Best Fold: {best_fold}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_fold_history = history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the accuracy/loss graphs for the best fold\nhistory_dict = best_fold_history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\naccuracy = history_dict['accuracy']\nval_accuracy = history_dict['val_accuracy']\n\nepochs = range(1, len(loss_values) + 1)\nfig, ax = plt.subplots(1, 2, figsize=(14, 6))\n\n# Plot the model accuracy vs Epochs\nax[0].plot(epochs, accuracy, 'r', label='Training accuracy')\nax[0].plot(epochs, val_accuracy, 'b', label='Validation accuracy')\nax[0].set_title(f'Training & Validation Accuracy - Best Fold ({best_fold})', fontsize=16)\nax[0].set_xlabel('Epochs', fontsize=16)\nax[0].set_ylabel('Accuracy', fontsize=16)\nax[0].legend()\n\n# Plot the loss vs Epochs\nax[1].plot(epochs, loss_values, 'r', label='Training loss')\nax[1].plot(epochs, val_loss_values, 'b', label='Validation loss')\nax[1].set_title(f'Training & Validation Loss - Best Fold ({best_fold})', fontsize=16)\nax[1].set_xlabel('Epochs', fontsize=16)\nax[1].set_ylabel('Loss', fontsize=16)\nax[1].legend()\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_accuracy = np.mean(all_validation_accuracy)\nmean_precision = np.mean(all_precision)\nmean_recall = np.mean(all_recall)\n\nprint(f'Mean Accuracy: {mean_accuracy}')\nprint(f'Mean Precision: {mean_precision}')\nprint(f'Mean Recall: {mean_recall}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\npredictions = mobile_model.predict(validation_images, steps=len(validation_images))\npredicted_labels = np.argmax(predictions, axis=1)\n\ntrue_labels = validation_images.classes\n# Print classification report\nprint(classification_report(true_labels, predicted_labels, target_names=train_images.class_indices.keys()))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import confusion_matrix\n# import seaborn as sns\n\n# predictions = mobile_model.predict(validation_images, steps=len(validation_images))\n# predicted_labels = np.argmax(predictions, axis=1)\n\n# true_labels = validation_images.classes\n\n# conf_matrix = confusion_matrix(true_labels, predicted_labels)\n\n# plt.figure(figsize=(8, 8))\n# sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n#             xticklabels=validation_images.class_indices.keys(),\n#             yticklabels=validation_images.class_indices.keys())\n# plt.title('Confusion Matrix')\n# plt.xlabel('Predicted Labels')\n# plt.ylabel('True Labels')\n# plt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}